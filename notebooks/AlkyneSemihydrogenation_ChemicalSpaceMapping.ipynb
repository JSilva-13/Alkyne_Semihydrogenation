{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook for the Data Analysis of Alkyne Semihydrogenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is inspired/based on work and analyses done in:\n",
    "\n",
    "* S. K. Kariofillis, A. G. Doyle *et al.*, *J. Am. Chem. Soc.* **2022**, *144*, 1045-1055. (https://pubs.acs.org/doi/10.1021/jacs.1c12203)\n",
    "* https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html (last accessed 10.08.22)\n",
    "* talktorial from the Volkamer lab: https://projects.volkamerlab.org/teachopencadd/talktorials/T006_compound_maximum_common_substructures.html (last accessed 10.08.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "#working with arrays\n",
    "import numpy as np\n",
    "from numpy import percentile\n",
    "\n",
    "#working with dataframes\n",
    "import os,sys,shutil,glob,pickle\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "#working with molecules\n",
    "from rdkit import Chem\n",
    "\n",
    "#Matplotlib, seaborn and associated plotting modules\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Load Data and Delete NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Workbook Sheet containing DFT calculated descriptors\n",
    "#********************************************************************\n",
    "df1 = pd.read_excel(\"DataSet_InternalAlkynes.xlsx\",sheet_name=\"DataSheet\")\n",
    "df1.drop(0,axis=0, inplace=True)\n",
    "df1.dropna(inplace=True)\n",
    "df1.set_index(\"Alkyne Number\", inplace=True)\n",
    "\n",
    "df2 = pd.read_excel(\"DataSet_TerminalAlkynes.xlsx\",sheet_name=\"DataSheet\")\n",
    "df2.drop(0,axis=0, inplace=True)\n",
    "df2.drop(684,axis=0,inplace=True) #borane weird valence structure\n",
    "df2.dropna(inplace=True)\n",
    "df2[\"Alkyne Number\"] = df2[\"Alkyne Number\"].astype(int) + len(df1)\n",
    "df2.set_index(\"Alkyne Number\", inplace=True)\n",
    "\n",
    "df = df1.append(df2)\n",
    "df.drop([\"NImag\"],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#drop different columns - SMILES and not averaged descriptors\n",
    "Smiles = pd.DataFrame(df[\"SMILES\"])\n",
    "df.drop([\"SMILES\"],axis=1, inplace=True)\n",
    "df.drop(columns=[\"x26\",\"x27\"], inplace = True)\n",
    "df.drop(columns=[\"x30\",\"x31\"], inplace = True)\n",
    "df.drop(columns=[\"x34\",\"x35\",\"x36\",\"x37\",\"x38\",\"x39\"], inplace = True)\n",
    "df.drop(columns=[\"x46\",\"x47\",\"x48\",\"x49\",\"x50\",\"x51\"], inplace = True)\n",
    "df.drop(columns=[\"x61\",\"x62\",\"x63\",\"x64\",\"x65\",\"x66\",\"x67\",\"x68\",\"x69\",\"x70\",\"x71\",\"x72\",\"x73\",\"x74\",\"x75\",\"x76\",\"x77\",\"x78\",\"x79\",\"x80\",\"x81\"], inplace = True)\n",
    "\n",
    "#to be checked for search for tested candidates\n",
    "inchi = Smiles[\"SMILES\"].map(Chem.MolFromSmiles).map(Chem.MolToInchi)\n",
    "Smiles = Smiles[~inchi.duplicated()]#.set_index('SMILES')\n",
    "\n",
    "#********************************************************************\n",
    "#Workbook Sheet containing SMILES of tested substrates\n",
    "#********************************************************************\n",
    "subs = pd.read_excel(\"DataSet_Substrates.xlsx\",sheet_name=\"DataSheet\")\n",
    "subs.drop([\"Substrate\"],axis=1, inplace=True)\n",
    "subs.dropna(inplace=True)\n",
    "subs[\"SMILES\"] = subs[\"SMILES\"].map(Chem.MolFromSmiles).map(Chem.MolToInchi)\n",
    "inchi_subs = subs\n",
    "\n",
    "#********************************************************************\n",
    "#Find candidates that were used as substrates\n",
    "#********************************************************************\n",
    "Candidates=inchi.where(inchi.isin(inchi_subs[\"SMILES\"])==True).dropna()\n",
    "condition=inchi_subs.index[inchi_subs[\"SMILES\"].isin(inchi)==True].tolist()\n",
    "condition2=inchi_subs.where(inchi.isin(inchi_subs[\"SMILES\"])==True).dropna()\n",
    "Candidates=pd.DataFrame(Candidates)\n",
    "Candidates[\"copy_index\"] = Candidates.index\n",
    "Candidates = pd.merge(Candidates, inchi_subs, on=['SMILES'], how='inner')\n",
    "Candidates.set_index(\"copy_index\",inplace=True)\n",
    "\n",
    "#********************************************************************\n",
    "#Workbook Sheet containing SMILES of literature substrates\n",
    "#********************************************************************\n",
    "lit_subs = pd.read_excel(\"DataSet_LiteratureSubstrates.xlsx\",sheet_name=\"DataSheet\")\n",
    "lit_subs.rename(columns=lit_subs.iloc[0], inplace=True)\n",
    "lit_subs.drop(0,axis=0, inplace=True)\n",
    "lit_subs.drop(lit_subs.iloc[:,7:],axis=1, inplace=True)\n",
    "lit_subs.drop([\"Substrate\"],axis=1, inplace=True)\n",
    "lit_subs.dropna(inplace=True)\n",
    "lit_subs[\"SMILES\"] = lit_subs[\"SMILES\"].map(Chem.MolFromSmiles).map(Chem.MolToInchi)\n",
    "lit_inchi_subs = lit_subs\n",
    "\n",
    "#********************************************************************\n",
    "#Find candidates that were used in literature\n",
    "#********************************************************************\n",
    "lit_Candidates=inchi.where(inchi.isin(lit_inchi_subs[\"SMILES\"])==True).dropna()\n",
    "lit_condition=lit_inchi_subs.index[lit_inchi_subs[\"SMILES\"].isin(inchi)==True].tolist()\n",
    "lit_condition2=lit_inchi_subs.where(inchi.isin(lit_inchi_subs[\"SMILES\"])==True).dropna()\n",
    "lit_Candidates=pd.DataFrame(lit_Candidates)\n",
    "lit_Candidates[\"copy_index\"] = lit_Candidates.index\n",
    "lit_Candidates = pd.merge(lit_Candidates, lit_inchi_subs, on=['SMILES'], how='inner')\n",
    "lit_Candidates.set_index(\"copy_index\",inplace=True)\n",
    "lit_Candidates[\"Number of Occurences\"]=lit_Candidates[\"Number of Occurences\"].astype(float)\n",
    "lit_Candidates[\"Average Yield\"]=lit_Candidates[\"Average Yield\"].astype(float)\n",
    "\n",
    "#Only Candidates that occured three times or more\n",
    "lit_Candidates=lit_Candidates.where(lit_Candidates[\"Number of Occurences\"]>2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Preprocessing of DFT Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Standardize and eliminate collinear features\n",
    "#********************************************************************\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# standardize\n",
    "df=pd.DataFrame(scale(df),index=df.index, columns=df.columns)\n",
    "\n",
    "# drop zero-variance features\n",
    "zero_std_cols = df.columns[df.std() == 0]\n",
    "df=df[df.columns.difference(zero_std_cols)]\n",
    "\n",
    "print (f\"Dropping {len(zero_std_cols)} features {zero_std_cols}\")\n",
    "\n",
    "# drop highly correlated features\n",
    "df_corr = df.corr().abs()\n",
    "upper = df_corr.where(np.triu(np.ones(df_corr.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "df = df.drop(to_drop, axis=1)\n",
    "\n",
    "print (f\"Dropping {len(to_drop)} features {to_drop}\")\n",
    "print (f\"Number of features left:  {len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Pearson Correlation Matrix vor Visualization\n",
    "#********************************************************************\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(df_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(3)\n",
    "ax.tick_params(length=12,width=3)\n",
    "ax.tick_params(which='minor', length=6, width=3)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True, sep=100)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(df_corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0, linewidths=.5)\n",
    "cbar = ax.collections[0].colorbar\n",
    "# here set the labelsize by 20\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "\n",
    "fig.suptitle('Correlation matrix of features', fontsize=25)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.savefig('Correlation_Matrix.tiff',dpi=600, pad_inches = .1, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Clustering with PCA & UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Create PCA and UMAP embeddings from features\n",
    "#********************************************************************\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "\n",
    "# define the dimensionalities of the reduced representation to study\n",
    "dims = [len(df.columns), 30, 20, 10, 5, 2]\n",
    "\n",
    "# dictionary to store data at different levels of dimensionality reduction\n",
    "dfs={}\n",
    "\n",
    "# UMAP section\n",
    "n_neighbors = np.int(np.sqrt(df.shape[1]))\n",
    "for dim in dims:\n",
    "    key = f\"umap{dim}\"\n",
    "    dfs[key] = pd.DataFrame(UMAP(n_components=dim, n_neighbors=n_neighbors, random_state=42).fit_transform(df),\n",
    "                            index=df.index)\n",
    "# PCA section\n",
    "pc = pd.DataFrame(PCA(n_components=None).fit_transform(df), index=df.index)\n",
    "for dim in dims:\n",
    "    key = f\"pc{dim}\"\n",
    "    dfs[key] = pc.iloc[:, :dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Visualization of the embeddings\n",
    "#********************************************************************\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6)) \n",
    "dfs['pc2'].columns = ['PC1', 'PC2']\n",
    "dfs['umap2'].columns = ['UMAP1', 'UMAP2']\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------#\n",
    "axs[0].scatter(x='PC1', y='PC2', data=dfs['pc2'], s=20, alpha=0.7, linewidth=0.25,\n",
    "                  edgecolor='face')\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axs[0].spines[axis].set_linewidth(3)\n",
    "axs[0].tick_params(length=12,width=3)\n",
    "axs[0].set_ylim([-12,12])\n",
    "axs[0].set_xlim([-10,30])\n",
    "axs[0].xaxis.set_minor_locator(plt.MaxNLocator(4))\n",
    "axs[0].xaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "axs[0].yaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "axs[0].set_yticks([-9,-3,3,9], minor=True)\n",
    "axs[0].set_xticks([-5,5,15,25], minor=True)\n",
    "axs[0].tick_params(which='minor', length=6, width=3,labelsize = 15)\n",
    "axs[0].set_title(\"PC Projection\", fontsize=18)\n",
    "axs[0].set_xlabel('PC1', fontsize = 15)\n",
    "axs[0].set_ylabel('PC1', fontsize = 15)\n",
    "#-----------------------------------------------------------------------------------------------------#\n",
    "axs[1].scatter(x='UMAP1', y='UMAP2', data=dfs['umap2'], s=20, alpha=0.7, linewidth=0.25,\n",
    "                  edgecolor='face')\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axs[1].spines[axis].set_linewidth(3)\n",
    "axs[1].tick_params(length=12,width=3)\n",
    "axs[1].set_ylim([-12.5,22.5])\n",
    "axs[1].set_xlim([-10,25])\n",
    "axs[1].set_xticks([-10,-3,4,11,18,25], major=True)\n",
    "axs[1].set_xticks([-6.5,0.5,7.5,14.5,21.5], minor=True)\n",
    "axs[1].set_yticks([-12.5,-5.5,1.5,8.5,15.5,22.5],major=True)\n",
    "axs[1].set_yticks([-9,-2,5,12,19], minor=True)\n",
    "axs[1].tick_params(which='minor', length=6, width=3,labelsize = 15)\n",
    "axs[1].set_title(\"UMAP Projection\", fontsize=18)\n",
    "axs[1].set_xlabel('UMAP1', fontsize = 15)\n",
    "axs[1].set_ylabel('UMAP2', fontsize = 15)\n",
    "#-----------------------------------------------------------------------------------------------------#\n",
    "\n",
    "plt.tight_layout(h_pad=0.5, w_pad=5, pad=3)\n",
    "#fig.savefig('PCAvsUMAP.tiff',dpi=600, pad_inches = .1, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationalize number of optimal clusters and reduced representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial silhouette scores for number of reduced representations. The silhouette score should be as high as possible, while little fluctuations in score with different reduced representations indicate the optimal number of UMAPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Silhouette Score Analysis for PCA and UMAP\n",
    "#********************************************************************\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster, fclusterdata\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------#\n",
    "def silhouette_scores_hierarchical(data, n_cls_list):\n",
    "    \"\"\"helper function to compute a silhouette score for hierarchical clustering using Ward linkage\"\"\"\n",
    "    z = linkage(data, method='ward')\n",
    "    result = pd.Series(index=n_cls_list, dtype=float)\n",
    "    for n_cls in n_cls_list:\n",
    "        cls = fcluster(z, n_cls, criterion='maxclust')\n",
    "        result.loc[n_cls] = silhouette_score(data, cls)\n",
    "    return result\n",
    "#-----------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Define the numbeor of clusters to study\n",
    "N_CLS_list = list(range(5, 21))\n",
    "\n",
    "# populate silhouette scores for all number of clusters and all dimensionality reductions that are pre-calculated\n",
    "silh_scores = pd.DataFrame(index=N_CLS_list)\n",
    "for key, value in dfs.items():\n",
    "    silh_scores[key] = silhouette_scores_hierarchical(value, N_CLS_list)\n",
    "\n",
    "# plot the silhouette scores with visualized embeddings\n",
    "grouped=silh_scores.groupby(silh_scores.columns.str.startswith('umap'), axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "\n",
    "for (key, ax) in zip(grouped.groups.keys(), axes.flatten()):\n",
    "    grouped.get_group(key).plot(ax=ax)\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(3)\n",
    "    ax.tick_params(length=12,width=3,labelsize = 15)\n",
    "    ax.set_xlabel('Number of Clusters', fontsize = 15)\n",
    "    ax.set_ylabel('Average Silhouette Score', fontsize = 15)\n",
    "    ax.legend(loc=1,fontsize=12)\n",
    "    \n",
    "plt.tight_layout(h_pad=0.5, w_pad=5, pad=3)\n",
    "#fig.savefig('SilhouetteScore.tiff',dpi=600, pad_inches = .1, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to look for in the silhouette analysis:\n",
    "    \n",
    "    a) above average score for all clusters\n",
    "    b) uniform silhouette thickness\n",
    "    c) no wide fluctuations in size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is based on a scikit-learn Jupyter notebook (https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Silhouette Analysis for UMAP with 5 embeddings\n",
    "#********************************************************************\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "X=dfs[\"umap5\"]\n",
    "for n_clusters in range(5,20):\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------#\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from [-1,1], we opt for [-0.1, 1] for depiction purposes\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters)*10 is demarcate silhouette plots of individual clusters.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility (as chosen in the scikit-learn example).\n",
    "    \n",
    "    clusterer = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.3 * size_cluster_i, str(i), fontsize=12)\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax1.spines[axis].set_linewidth(3)\n",
    "    ax1.tick_params(length=12,width=3, labelsize=15)\n",
    "    #ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"Silhouette Coefficient Values\", fontsize=15)\n",
    "    ax1.set_ylabel(\"Cluster label\", fontsize=15)\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    #-----------------------------------------------------------------------------------------------------#\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------#\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral((cluster_labels.astype(float)) / n_clusters)\n",
    "    ax2.scatter(dfs['umap2'][\"UMAP1\"], dfs['umap2'][\"UMAP2\"], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax2.spines[axis].set_linewidth(3)\n",
    "    ax2.tick_params(length=12,width=3, labelsize=15)\n",
    "\n",
    "    ax2.set_xlabel(\"UMAP1\", fontsize=15)\n",
    "    ax2.set_ylabel(\"UMAP2\", fontsize=15)\n",
    "    ax2.set_xticks([-10,-3,4,11,18,25], major=True)\n",
    "    ax2.set_xticks([-6.5,0.5,7.5,14.5,21.5], minor=True)\n",
    "    ax2.set_yticks([-12.5,-5.5,1.5,8.5,15.5,22.5],major=True)\n",
    "    ax2.set_yticks([-9,-2,5,12,19], minor=True)\n",
    "    ax2.tick_params(which='minor', length=6, width=3)\n",
    "    #-----------------------------------------------------------------------------------------------------#\n",
    "    \n",
    "    plt.tight_layout(h_pad=0.5, w_pad=5, pad=3)\n",
    "    plt.show()\n",
    "    \n",
    "    #save the plot with optimal number of clusters after checking\n",
    "    #if i==5: #number to be changed here => (number of clusters - 1)\n",
    "    #    fig.savefig('SilhouetteAnalysis_6clusters.tiff',dpi=600, pad_inches = .1, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Generation of Dendrogram with Optimal Hyperparameters\n",
    "#********************************************************************\n",
    "\n",
    "# final number of clusters to produce\n",
    "NCLS = 6\n",
    "\n",
    "# linkage and clustering for selected featurization\n",
    "z = linkage(dfs['umap5'], method=\"ward\")\n",
    "cls = fcluster(z, NCLS, criterion='maxclust')\n",
    "\n",
    "# plot the dendrogram\n",
    "fig,ax=plt.subplots(figsize=(6, 6))\n",
    "_=dendrogram(z, truncate_mode='lastp', p=NCLS, show_contracted=True,\n",
    "             leaf_rotation=90, color_threshold=0)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(3)\n",
    "ax.tick_params(length=12,width=3,labelsize=15)\n",
    "ax.tick_params(which='minor', length=6, width=3)\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=3)\n",
    "\n",
    "#fig.savefig('Dendrogram.tiff',dpi=600, pad_inches = .1, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Plotting of Tested Substrates on Clustered Chemical Space Map\n",
    "#********************************************************************\n",
    "\n",
    "#Definition of color palette\n",
    "color_palette = [\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#F0E442\"]\n",
    "color_palette_rgb = [matplotlib.colors.to_rgb(i) for i in color_palette]\n",
    "\n",
    "#Plotting of clustered chemical space (p1) with star-shaped tested entries (p2), surrounded by circles (p3)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "p1 = plt.scatter(x=\"UMAP1\", y=\"UMAP2\", data=dfs['umap2'], s=20, alpha=0.7, linewidth=0.25, edgecolor='face',\n",
    "                cmap=matplotlib.colors.LinearSegmentedColormap.from_list(\"bla\",color_palette_rgb), c=cls)\n",
    "p2 = plt.scatter(x=\"UMAP1\", y=\"UMAP2\", data=dfs['umap2'].loc[Candidates.index],  s=70, alpha=0.7, linewidth=0.25, edgecolor='black', c=\"black\", marker=\"*\")\n",
    "p3 = plt.scatter(x=\"UMAP1\", y=\"UMAP2\", data=dfs['umap2'].loc[Candidates.index],  s=80, alpha=0.7, linewidth=1, edgecolor='black', facecolor=\"none\")\n",
    "\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(3)\n",
    "ax.tick_params(length=12,width=3, labelsize=15)\n",
    "\n",
    "ax.set_xlabel(\"UMAP1\", fontsize=15)\n",
    "ax.set_ylabel(\"UMAP2\", fontsize=15)\n",
    "ax.set_xticks([-10,-3,4,11,18,25], major=True)\n",
    "ax.set_xticks([-6.5,0.5,7.5,14.5,21.5], minor=True)\n",
    "ax.set_yticks([-12.5,-5.5,1.5,8.5,15.5,22.5],major=True)\n",
    "ax.set_yticks([-9,-2,5,12,19], minor=True)\n",
    "ax.tick_params(which='minor', length=6, width=3)\n",
    "\n",
    "plt.tight_layout(h_pad=0.5, w_pad=5, pad=3)\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig('Substrates_on_clusters.tiff',dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Plotting of Semihydrogenation Rates on Alkyne Chemical Space Map\n",
    "#********************************************************************\n",
    "\n",
    "#Plotting of clustered chemical space (p1) with harsher hydrogenation candidates (5 bar, 80 Â°C, 16 h) (p2)\n",
    "# and mild hydrogenation candidates (1 bar, 80 Â°C, 10 h) (p3)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "p1 = plt.scatter(x=\"UMAP1\", y=\"UMAP2\", data=dfs['umap2'], s=20, alpha=0.7, linewidth=0.25, edgecolor='face',\n",
    "                 c=\"lightgrey\")\n",
    "p2 = plt.scatter(x=\"UMAP1\", y=\"UMAP2\", data=dfs['umap2'].loc[Candidates.index.where(Candidates[\"Condition\"]==\"B\").dropna().astype(int)], s=Candidates[\"Rates\"].where(Candidates[\"Condition\"]==\"B\").dropna()/Candidates[\"Rates\"].max()*100+25, alpha=.7, linewidth=0.25, edgecolor='face', color=\"darkred\")\n",
    "p3 = plt.scatter(x=\"UMAP1\", y=\"UMAP2\", data=dfs['umap2'].loc[Candidates.index.where(Candidates[\"Condition\"]==\"A\").dropna().astype(int)], s=Candidates[\"Rates\"].where(Candidates[\"Condition\"]==\"A\").dropna()/Candidates[\"Rates\"].max()*100+25, alpha=.7, linewidth=0.25, edgecolor='face', color=\"#69d\")\n",
    "\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(3)\n",
    "ax.tick_params(length=12,width=3, labelsize=15)\n",
    "\n",
    "ax.set_xlabel(\"UMAP1\", fontsize=15)\n",
    "ax.set_ylabel(\"UMAP2\", fontsize=15)\n",
    "ax.set_xticks([-10,-3,4,11,18,25], major=True)\n",
    "ax.set_xticks([-6.5,0.5,7.5,14.5,21.5], minor=True)\n",
    "ax.set_yticks([-12.5,-5.5,1.5,8.5,15.5,22.5],major=True)\n",
    "ax.set_yticks([-9,-2,5,12,19], minor=True)\n",
    "ax.tick_params(which='minor', length=6, width=3)\n",
    "\n",
    "plt.tight_layout(h_pad=0.5, w_pad=5, pad=3)\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig('Susbstrate_Rates_on_Space.tiff',dpi=600, pad_inches = .1, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Plotting of Literature Reported Semihydrogenation Yields \n",
    "#of Substrates Occurring more than 2 times\n",
    "#********************************************************************\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "p1 = plt.scatter(x=\"UMAP1\", y=\"UMAP2\", data=dfs['umap2'], s=20, alpha=0.7, linewidth=0.25, edgecolor='face',\n",
    "                 c=\"lightgrey\")\n",
    "\n",
    "p2 = plt.scatter(x=\"UMAP1\", y=\"UMAP2\", data=dfs['umap2'].loc[lit_Candidates.index], s=lit_Candidates[\"Number of Occurences\"]/lit_Candidates[\"Number of Occurences\"].max()*200, alpha=.7, linewidth=0.25, edgecolor='face', c=lit_Candidates[\"Average Yield\"], cmap=sns.dark_palette(\"#69d\", reverse=True, as_cmap=True))\n",
    "\n",
    "cbar = plt.colorbar(p2)\n",
    "plt.clim(0,100)\n",
    "cbar.ax.tick_params(labelsize=12) \n",
    "\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(3)\n",
    "ax.tick_params(length=12,width=3, labelsize=15)\n",
    "\n",
    "ax.set_xlabel(\"UMAP1\", fontsize=15)\n",
    "ax.set_ylabel(\"UMAP2\", fontsize=15)\n",
    "ax.set_xticks([-10,-3,4,11,18,25], major=True)\n",
    "ax.set_xticks([-6.5,0.5,7.5,14.5,21.5], minor=True)\n",
    "ax.set_yticks([-12.5,-5.5,1.5,8.5,15.5,22.5],major=True)\n",
    "ax.set_yticks([-9,-2,5,12,19], minor=True)\n",
    "ax.tick_params(which='minor', length=6, width=3)\n",
    "\n",
    "plt.tight_layout(h_pad=0.5, w_pad=5, pad=3)\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig('Literature_on_clusters.tiff',dpi=600, pad_inches = .1, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Selection of Molecules from Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Central Molecule of Each Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Selection of Central Molecules in Each Cluster\n",
    "#********************************************************************\n",
    "from scipy.spatial.distance import cdist\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# build rdkit molecules for all candidates\n",
    "mols = pd.Series(Smiles[\"SMILES\"].map(Chem.MolFromSmiles), index=df.index).to_frame('mol')\n",
    "features='umap5'\n",
    "\n",
    "# How many central molecules to display?\n",
    "n_per_cluster = 5\n",
    "                                                                            \n",
    "# store central candidates for\n",
    "cands=[]\n",
    "\n",
    "for group, data in mols.groupby(cls):\n",
    "    # get descriptor data for this cluster\n",
    "    desc_data=dfs[features].loc[data.index]\n",
    "    \n",
    "    # compute distances of these molecules to their center\n",
    "    dists=pd.Series(cdist([desc_data.mean()], desc_data)[0],\n",
    "                    index=desc_data.index)\n",
    "    \n",
    "    # select top n central molecules\n",
    "    selected=dists.sort_values().head(n_per_cluster).index\n",
    "    \n",
    "    smi=mols.loc[selected]['mol'].map(Chem.MolToSmiles)\n",
    "    smi=smi.reset_index(drop=True).to_frame(f\"Cluster{group}\")\n",
    "    cands.append(smi)\n",
    "    \n",
    "    print (f\"Cluster {group}, n molecules: {len(data)}\")\n",
    "    ms = data['mol'].loc[selected]\n",
    "    display(Draw.MolsToGridImage(ms, molsPerRow=n_per_cluster))\n",
    "    img=Draw.MolsToGridImage(ms,molsPerRow=n_per_cluster,subImgSize=(200,200),returnPNG=False)\n",
    "    \n",
    "    #Saving of every single molecule selection for cluster\n",
    "    #img.save(\"Cluster_\"+str(group)+'.tiff')   \n",
    "\n",
    "cands = pd.concat(cands, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Common Substructure (MCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further information about the applied algorithm can be found here: http://www.rdkit.org/docs/Cookbook.html#using-custom-mcs-atom-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "from ipywidgets import interact, fixed, widgets\n",
    "\n",
    "from rdkit import Chem, Geometry\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import rdFMCS\n",
    "from rdkit.Chem import PandasTools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Generate Dataframe Containing SMILES \n",
    "#********************************************************************\n",
    "compound_df = df1.append(df2)\n",
    "compound_df.drop([\"NImag\"],axis=1, inplace=True)\n",
    "compound_df.drop(compound_df.columns[1:],axis=1,inplace=True)\n",
    "compound_df[\"ID\"]=compound_df.index\n",
    "print(\"Dataframe shape:\", compound_df.shape)\n",
    "compound_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Create SDF file with all molecules and IDs\n",
    "#********************************************************************\n",
    "\n",
    "PandasTools.AddMoleculeColumnToFrame(compound_df,'SMILES','ID') # pp = doesn't work for me\n",
    "PandasTools.WriteSDF(compound_df, 'SDF.sdf', molColName='ID', properties=list(compound_df.columns))\n",
    "sdf='SDF.sdf'\n",
    "supplier = Chem.ForwardSDMolSupplier(sdf)\n",
    "mols1 = list(supplier)\n",
    "\n",
    "print(f\"Set with {len(mols1)} molecules loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Apply FMCS algorithm and attribute MCS to every cluster\n",
    "#********************************************************************\n",
    "\n",
    "mols_df=pd.DataFrame(mols1)\n",
    "\n",
    "mols_df=mols_df.groupby(cls)\n",
    "for group, data in mols_df:\n",
    "    mols=data.iloc[:,0].values.tolist()\n",
    "    print(f\"Set with {len(mols)} molecules loaded.\")\n",
    "    mcs1 = rdFMCS.FindMCS(mols,threshold=0.50) #this value can be changed to assess for percentage of all molecules\n",
    "    print(f\"MCS1 contains {mcs1.numAtoms} atoms and {mcs1.numBonds} bonds.\")\n",
    "    print(\"MCS SMARTS string:\", mcs1.smartsString)\n",
    "    \n",
    "    # Draw substructure from Smarts\n",
    "    m1 = Chem.MolFromSmarts(mcs1.smartsString)\n",
    "    display(Draw.MolToImage(m1, legend=\"Cluster \"+str(group)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Function to highlight substructure in selected molecules\n",
    "#********************************************************************\n",
    "\n",
    "def highlight_molecules(molecules, mcs, number, label=True, same_orientation=True, **kwargs):\n",
    "    \"\"\"Highlight the MCS in our query molecules\"\"\"\n",
    "    molecules = deepcopy(molecules)\n",
    "    # convert MCS to molecule\n",
    "    pattern = Chem.MolFromSmarts(mcs.smartsString)\n",
    "    # find the matching atoms in each molecule\n",
    "    matching = [molecule.GetSubstructMatch(pattern) for molecule in molecules[:number]]\n",
    "\n",
    "    legends = None\n",
    "    if label is True:\n",
    "        legends = [x.GetProp(\"_Name\") for x in molecules]\n",
    "\n",
    "    # Align by matched substructure so they are depicted in the same orientation\n",
    "    # Adapted from: https://gist.github.com/greglandrum/82d9a86acb3b00d3bb1df502779a5810\n",
    "    if same_orientation:\n",
    "        mol, match = molecules[0], matching[0]\n",
    "        AllChem.Compute2DCoords(mol)\n",
    "        coords = [mol.GetConformer().GetAtomPosition(x) for x in match]\n",
    "        coords2D = [Geometry.Point2D(pt.x, pt.y) for pt in coords]\n",
    "        for mol, match in zip(molecules[1:number], matching[1:number]):\n",
    "            if not match:\n",
    "                continue\n",
    "            coord_dict = {match[i]: coord for i, coord in enumerate(coords2D)}\n",
    "            AllChem.Compute2DCoords(mol, coordMap=coord_dict)\n",
    "\n",
    "    return Draw.MolsToGridImage(\n",
    "        molecules[:number],\n",
    "        legends=legends,\n",
    "        molsPerRow=5,\n",
    "        highlightAtomLists=matching[:number],\n",
    "        subImgSize=(200, 200),\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_molecules(mols, mcs1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Diversity of the Clustering Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Helper Functions for Sampling\n",
    "#********************************************************************\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "def sample_dist(data):\n",
    "    dists = pdist(data)\n",
    "    return [ min(dists), np.mean(dists), max(dists)]\n",
    "\n",
    "def kenStone(X, k, metric='euclidean'):\n",
    "    # safety checks\n",
    "    assert isinstance(k, int)\n",
    "    assert k >= 2\n",
    "    assert k <= X.shape[0]\n",
    "    # distance matrix\n",
    "    d = squareform(pdist(X, metric))\n",
    "    # seed pick the pair that's furthest apart\n",
    "    selected = list(np.unravel_index(np.argmax(d), d.shape))\n",
    "    while len(selected) < k:\n",
    "   \n",
    "        #add sample whose minimum distance to the selected samples is largest\n",
    "        selected.append(np.argmax(d[selected,].min(axis=0)))\n",
    "    return selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a handful of umaps with various random seeds\n",
    "umaps = []\n",
    "for i in range(50):\n",
    "    umaps.append(pd.DataFrame(UMAP(n_components=5, n_neighbors=n_neighbors).fit_transform(df),\n",
    "                          index=df.index))\n",
    "    \n",
    "# add the original umap that was used for clustering\n",
    "umaps = [dfs['umap5']] + umaps\n",
    "\n",
    "# selection of dataset to use\n",
    "dat = umaps[27]\n",
    "NCLS=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Clustering\n",
    "#********************************************************************\n",
    "\n",
    "ret_cls = []\n",
    "for dat in umaps:\n",
    "    # clustering\n",
    "    z = linkage(dat, method=\"ward\")\n",
    "    cls = fcluster(z, NCLS, criterion='maxclust')\n",
    "    \n",
    "    selected = []\n",
    "    for group, d in dat.groupby(cls):\n",
    "        \n",
    "        # compute distances of these molecules to their center\n",
    "        dists=pd.Series(cdist([d.mean()], d)[0],\n",
    "                        index=d.index)\n",
    "        \n",
    "        # select top n central molecules\n",
    "        selected.append(dists.sort_values().index[0])\n",
    "        \n",
    "    dcls = sample_dist(dat.loc[selected])\n",
    "    ret_cls.append(dcls)\n",
    "    \n",
    "ret_cls = pd.DataFrame(ret_cls, columns=[ 'clustering min. dist', 'clustering avg. dist', 'clustering max. dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Kennard-Stone algorithm\n",
    "#********************************************************************\n",
    "\n",
    "ret_ks = []\n",
    "for dat in umaps:\n",
    "    ks = kenStone(dat, NCLS)\n",
    "    dks = sample_dist(dat.iloc[ks])\n",
    "    ret_ks.append(dks)\n",
    "\n",
    "ret_ks = pd.DataFrame(ret_ks, columns=[ 'ks min dist', 'ks avg dist', 'ks max dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Random Sampling\n",
    "#********************************************************************\n",
    "\n",
    "ret_rnd = []\n",
    "for dat in umaps:\n",
    "    for i in range(100):\n",
    "        ret_rnd.append(sample_dist(dat.sample(NCLS)))\n",
    "ret_rnd = pd.DataFrame(ret_rnd, columns=[ 'random min. dist', 'random avg. dist', 'random max. dist'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************\n",
    "#Plots\n",
    "#********************************************************************\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(18, 6))\n",
    "ret_cls.plot(kind='hist', histtype='step', facecolor='#008000', edgecolor='k', \n",
    "             fill=True,\n",
    "             subplots=True, ax=ax, color='black', bins=25, xlim=(-1, 20), density=True)\n",
    "\n",
    "ret_rnd.plot(kind='hist', histtype='step', color='#0000C0', linewidth=2, linestyle='--',\n",
    "             subplots=True, ax=ax, bins=25, xlim=(-1, 20), density=True)\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax[0].spines[axis].set_linewidth(3)\n",
    "    ax[1].spines[axis].set_linewidth(3)\n",
    "    ax[2].spines[axis].set_linewidth(3)\n",
    "ax[0].tick_params(length=12,width=3,labelsize=15)\n",
    "ax[1].tick_params(length=12,width=3,labelsize=15)\n",
    "ax[2].tick_params(length=12,width=3,labelsize=15)\n",
    "ax[0].tick_params(which='minor', length=6, width=3,labelsize=15)\n",
    "ax[1].tick_params(which='minor', length=6, width=3,labelsize=15)\n",
    "ax[2].tick_params(which='minor', length=6, width=3,labelsize=15)\n",
    "\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=3)\n",
    "ax[0].set_ylabel('Density',fontsize=15)\n",
    "ax[1].set_ylabel('Density',fontsize=15)\n",
    "ax[2].set_ylabel('Density',fontsize=15)\n",
    "\n",
    "ax[1].legend(loc=\"upper left\")\n",
    "ax[2].legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()\n",
    "#fig.savefig('RandomvsClusteringSelection.tiff',dpi=600, pad_inches = .1, bbox_inches = 'tight')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
